---
title: "Pure Python"
description: "Build distributed agents from scratch with full control over execution"
---

## When to use Pure Python

- You want full control over the agent loop
- You don't need LLM framework integrations
- You're building custom orchestration logic
- You want minimal dependencies

## Create an agent

```bash
rayai create-agent my_agent --framework python
```

## The `@tool` decorator

Define tools that automatically execute on Ray workers:

```python
from rayai import tool

@tool(desc="Search the web", num_cpus=1, memory="512MB")
def search_web(query: str) -> str:
    return f"Results for: {query}"

# Call directly - Ray execution is automatic
result = search_web(query="Python tutorials")
```

## The `@agent` decorator

Mark a class as a deployable agent:

```python
from rayai import agent

@agent(num_cpus=2, memory="4GB", num_replicas=2)
class MyAgent:
    def run(self, data: dict) -> dict:
        return {"response": "Hello!"}
```

## Parallel tool execution

Run multiple tools simultaneously:

```python
from rayai import execute_tools

results = execute_tools([
    (search_web, {"query": "Python tutorials"}),
    (fetch_data, {"url": "https://api.example.com"}),
    (analyze_text, {"text": "Some content"}),
], parallel=True)
```

## Use with agent frameworks

Plain Python functions can be used directly with any agent framework. `RayToolWrapper` converts them to framework-compatible tools that execute on Ray:

```python
from rayai.adapters import RayToolWrapper, AgentFramework

# Plain Python functions - no decorators needed
def search(query: str) -> str:
    """Search the web for information."""
    return f"Results for: {query}"

def add(a: int, b: int) -> int:
    """Add two numbers together."""
    return a + b

# Convert to LangChain tools
wrapper = RayToolWrapper(framework=AgentFramework.LANGCHAIN)
lc_tools = wrapper.wrap_tools([search, add], num_cpus=1)

# Or convert to Pydantic AI tools
wrapper = RayToolWrapper(framework=AgentFramework.PYDANTIC)
pydantic_tools = wrapper.wrap_tools([search, add], num_cpus=1)
```

<Tip>
Type annotations and docstrings are preserved for LLM schema generation. Always include them for best results.
</Tip>

## Next steps

<CardGroup cols={2}>
  <Card title="LangChain Integration" icon="link" href="/frameworks/langchain">
    Use LangChain and LangGraph with distributed tools
  </Card>
  <Card title="Pydantic AI" icon="cube" href="/frameworks/pydantic">
    Type-safe agents with Pydantic AI
  </Card>
</CardGroup>
