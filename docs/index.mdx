---
title: "Introduction"
description: "Distribute agentic workloads on Ray"
---

## Why use Superserve?
Superserve connects any agent framework (Langchain, Pydantic AI, and more) to Ray's distributed compute, 
letting you run parallel tool calls across clusters, mix tools from different frameworks, and execute AI-generated code in isolated sandboxes.

<Card
  title="Start here"
  icon="rocket"
  href="/quickstart"
  horizontal
>
  Follow our three step quickstart guide.
</Card>

## How it works

<Columns cols={2}>
  <Card
    title="CLI"
    icon="terminal"
    href="https://pypi.org/project/superserve/"
  >
    Use command line to generate production-ready agents in seconds
  </Card>
  <Card
    title="Framework Agnostic"
    icon="plug"
    href="/frameworks/build-from-scratch"
  >
    Use tools from different frameworks together (Langchain, Pydantic AI)
  </Card>
    <Card
    title="Batch tool"
    icon="tasks"
    href="/tools/native/batch"
  >
    Give LLMs a batch tool to distribute ANY tool calls across a cluster asynchronously
  </Card>
  <Card
    title="Code Sandboxes"
    icon="code"
    href="/tools/native/sandbox"
  >
    Run AI-generated code safely in isolated sandbox environments
  </Card>
</Columns>
