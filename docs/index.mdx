---
title: "Superserve"
description: "Deploy AI agents to the cloud. One command."
---

```bash
pip install superserve
superserve login
superserve deploy agent.py
```

Your agent is now running in an isolated sandbox with an HTTPS endpoint, streaming responses, persistent storage, and encrypted secrets. You didn't change your code.

```bash
$ superserve run my-agent "Analyze the error logs in /var/log and suggest fixes"

Analyzing /var/log/syslog and /var/log/auth.log...

Found 3 issues:
1. SSH brute-force attempts from 192.168.1.105 (847 failed logins in 24h)
   → Add to /etc/hosts.deny or configure fail2ban
2. Disk space warning on /dev/sda1 (94% full)
   → Clean /var/log/journal — currently using 2.3GB
3. OOM killer invoked twice for postgres (PID 1834, 2291)
   → Increase vm.overcommit_ratio or add swap

Completed in 4.7s
```

<CardGroup cols={2}>
  <Card title="Quickstart" icon="bolt" href="/quickstart">
    Deploy an agent in 2 minutes
  </Card>
  <Card title="Zero-Config Deploy" icon="wand-magic-sparkles" href="/zero-config">
    How it works under the hood
  </Card>
  <Card title="SDK" icon="code" href="/sdk">
    TypeScript client, React hooks
  </Card>
  <Card title="CLI" icon="terminal" href="/cli">
    All commands and flags
  </Card>
</CardGroup>

---

## What you get

Every deployed agent runs in its own [Firecracker microVM](https://firecracker-microvm.github.io/). Each session gets:

- **Isolated sandbox** — own filesystem, network, and compute. Nothing is shared between sessions.
- **Persistent workspace** — files survive across turns and restarts. Resume a conversation days later and the agent picks up where it left off.
- **Encrypted secrets** — API keys are encrypted at rest, injected at runtime, never logged or returned by the API.
- **Real-time streaming** — tokens and tool calls stream back via SSE as they happen.
- **Sub-second cold starts** — pre-built templates mean your agent starts in ~400ms.

---

## Works with any agent framework

Zero-config deploy works with anything that reads from `input()` and writes to `print()` — or anything that exposes an HTTP endpoint.

<CardGroup cols={3}>
  <Card title="Claude Agent SDK">
    ```bash
    superserve deploy agent.py
    ```
  </Card>
  <Card title="OpenAI Agents SDK">
    ```bash
    superserve deploy agent.py
    ```
  </Card>
  <Card title="Your own code">
    ```bash
    superserve deploy server.py --port 8000
    ```
  </Card>
</CardGroup>

Same command. Same infrastructure. The framework doesn't matter — Superserve runs your code as-is.
