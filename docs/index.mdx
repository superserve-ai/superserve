---
title: "Superserve"
description: "Agent sandboxes with sessions, streaming, and zero-config deploys"
---

## The problem

You built an agent that works on your laptop. Now you need other people to use it.

Scaffolding a server is easy — any coding agent can generate a FastAPI wrapper in 30 seconds. The hard part is everything that breaks in production:

- **Isolation** — your agent executes arbitrary code, writes files, spawns processes. One user's session must never see another's data. Getting this wrong is a security incident, not a bug.
- **Stateful sessions** — a conversation is multi-turn. The agent needs to keep files, variables, and context between messages — and resume correctly days later, even after the underlying process restarts. Race conditions, stale state, and session leaks are hard to test and harder to debug.
- **Streaming under real conditions** — SSE that works on localhost breaks when clients disconnect mid-stream, back-pressure builds up, or the agent takes 3 minutes on a tool call. Handling timeouts, heartbeats, and reconnection correctly takes iteration.
- **Secrets at rest** — not env vars baked into a Docker image. Actually encrypted, actually scoped per agent, actually never logged or returned by the API.
- **Cold starts** — a 10-second sandbox boot kills the conversational UX. You need sub-second starts, which means pre-built images, not on-demand builds.

Sandbox platforms like E2B and Modal give you isolated compute. But you still build the session layer, the streaming layer, the deploy pipeline, and the API yourself — and you own every production edge case above.

## The fix

```bash
pip install superserve
superserve deploy agent.py
```

Your agent is now a production API. Each session runs in its own [Firecracker microVM](https://firecracker-microvm.github.io/) with:

- **Hardware-level isolation** — separate kernel, filesystem, and network per session. Agents can execute code and use tools without risk of cross-session data leaks.
- **Durable workspace** — the agent's filesystem persists across turns and restarts. Resume a conversation days later and every file is exactly where the agent left it.
- **Session management** — multi-turn conversation state handled by the platform. No database, no serialization, no race conditions to debug.
- **Production streaming** — SSE with heartbeats, backpressure handling, and graceful disconnect recovery. Works for responses that take seconds or minutes.
- **Secrets encrypted at rest** — scoped per agent, injected at runtime, never in images or logs.
- **~400ms cold starts** — pre-built sandbox templates with dependencies baked in. Fast enough for conversational UX.

The same script that runs with `python agent.py` on your laptop runs in the cloud — the production concerns above are handled for you.

```bash
$ superserve run my-agent "Review the error handling in src/auth.ts — are we leaking stack traces?"

Analyzing src/auth.ts and src/middleware/auth.ts...

Found 2 issues:
1. Line 47: `catch(e) { res.json({ error: e.message }) }`
   Leaks internal error details to clients. Return a generic 500 and
   log the full error server-side.
2. Line 82: Bare `catch {}` swallows errors silently.
   At minimum, log the error. Better: re-throw after logging.

The rest of the error handling looks correct — login() and refreshToken()
both use structured error responses.

Completed in 3.8s
```

---

## Works with any agent framework

Superserve runs your code as-is. No SDK lock-in, no framework requirements.

<CardGroup cols={3}>
  <Card title="Claude Agent SDK">
    ```bash
    superserve deploy agent.py
    ```
  </Card>
  <Card title="OpenAI Agents SDK">
    ```bash
    superserve deploy agent.py
    ```
  </Card>
  <Card title="Your own HTTP server">
    ```bash
    superserve deploy server.py --port 8000
    ```
  </Card>
</CardGroup>

Same command. Same infrastructure. Same streaming, sessions, and secrets.

---

<CardGroup cols={2}>
  <Card title="Quickstart" icon="bolt" href="/quickstart">
    Deploy an agent in 2 minutes
  </Card>
  <Card title="Zero-Config Deploy" icon="wand-magic-sparkles" href="/zero-config">
    How it works under the hood
  </Card>
  <Card title="SDK" icon="code" href="/sdk">
    TypeScript client, React hooks
  </Card>
  <Card title="CLI" icon="terminal" href="/cli">
    All commands and flags
  </Card>
</CardGroup>
